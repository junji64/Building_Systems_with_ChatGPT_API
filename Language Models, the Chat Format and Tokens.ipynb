{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fc75cb02",
   "metadata": {},
   "source": [
    "# Building Systems with the ChatGPT API\n",
    "\n",
    "ChatGPT API를 사용하여 시스템을 구축하는 과정에 오신 것을 환영합니다.\n",
    "\n",
    "시스템을 구축하는 과정에는 단일 프롬프트나 대규모 언어 모델에 대한 단일 호출보다 훨씬 더 많은 것이 필요합니다.\n",
    "여기에서 LLM을 사용하여 복잡한 애플리케이션을 구축하기 위한 모범 사례를 공유하고자 합니다. 우리는 언어 모델에 대한 여러 호출을 연결하고 이전 호출의 출력에 따라 다른 명령을 사용하고 때로는 외부 소스에서 항목을 조회하는 종단 간 고객 지원 시스템을 구축하는 실행 예제를 사용했습니다.\n",
    "\n",
    "예를 들어 \"판매 중인 TV에 대해 알려주세요.\"와 같은 사용자 입력이 주어지면 다음 단계를 사용하여 이를 처리합니다.\n",
    "먼저 **입력 내용을 평가**하여 증오심 표현과 같은 문제가 있는 콘텐츠가 포함되어 있지 않은지 확인할 수 있습니다. 다음으로 시스템은 **입력을 처리**합니다. 이것이 **어떤 유형의 쿼리인지 식별**합니다. 불만 또는 제품 정보 요청 등입니까? 제품 문의라고 판단되면 TV에 대한 관련 정보를 검색하고 언어 모델을 사용하여 유용한 답변을 작성합니다.\n",
    "\n",
    "마지막으로 **출력을 확인**하여 부정확하거나 부적절한 답변과 같은 문제가 없는지 확인합니다. 이 과정에서 확인할 수 있는 주제는 **응용 프로그램이 종종 최종 사용자에게 보이지 않는 여러 내부 단계를 필요로 한다는 것입니다**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bf42ef8",
   "metadata": {},
   "source": [
    "#  Language Models, the Chat Format and Tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0807e3b3",
   "metadata": {},
   "source": [
    "## Large Language Model\n",
    "\n",
    "##### Text generation process\n",
    "\n",
    "| I love eating |  -------------------------------------------------- |\n",
    "| ------------------|-------------------|\n",
    "| [prompt] | bagles with cream cheese |\n",
    "|        | my mothers's meatloaf |\n",
    "|        | out with friends |\n",
    "\n",
    "##### Supervised Learning (x --> y)\n",
    "\n",
    "Restaurant reviewers sentiment classification\n",
    "\n",
    "| Input x |  Output y |\n",
    "| ------------------|-------------------|\n",
    "| The pastromi sandwich was great | positive |\n",
    "| Service was slow and the food was so~so | netative |\n",
    "| The earl grey tea was fantastic. | positive |\n",
    "| [Best pizza I've aver had!] | [positive] |\n",
    "\n",
    "\n",
    "Get labeled data >> Train AI model on data >> Deploy & vall model\n",
    "\n",
    "##### LLM : How it works\n",
    "\n",
    "A language model is built by using supervised learning(x->y) to repeatedly predict the next word.\n",
    "\n",
    "My favorite food is a bagel with cream cheese and lox.\n",
    "\n",
    "| Input x |  Output y |\n",
    "| ------------------|-------------------|\n",
    "| My favorite food is a | bagel |\n",
    "| My favorite food is a bagel | with |\n",
    "| My favorite food is a bagel with | cream |\n",
    "| My favorite food is a bagel with cream | cheese |\n",
    "\n",
    "\n",
    "##### Two types of large language models (LLMs)\n",
    "\n",
    "**Base LLM**\n",
    "\n",
    "Predicts next word, based on text training data\n",
    "\n",
    "*[Once up a time, there was a unicorn]*\n",
    "<br>\n",
    "that lived in a magical forest with all her unicorn friends.\n",
    "<br>\n",
    "<br>\n",
    "*[What is the capital of France?]*\n",
    "<br>\n",
    "What is France's largest city?\n",
    "<br>\n",
    "What is France's population?\n",
    "<br>\n",
    "What is the currency of France?\n",
    "\n",
    "\n",
    "**Instruction Tuned LLM**\n",
    "\n",
    "Tries to follow instructions\n",
    "\n",
    "*[What is teh capital of France?]*\n",
    "<br>\n",
    "The capital of France is Paries.\n",
    "\n",
    "**Getting from a Base LLM to an Instruction Tuned LLM**\n",
    "1. Train a Base LLm on a lot of data.\n",
    "2. Further train the model:\n",
    "  * Fine-tune on examples of where the output follows on input instruction.\n",
    "  * Obtain human-ratings of the quality of different LLM outputs, on criteria such as whether it is helpfun, honest and harmless\n",
    "  * Tune LLM to increase probability that it generates the more highly rated outputs (using RLHF: Reinforcement Learning from Human Feedback)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01e79ede",
   "metadata": {},
   "source": [
    "## Setup\n",
    "#### Load the API key and relevant Python libaries.\n",
    "이 과정에서는 OpenAI API 키를 로드하는 몇 가지 코드를 제공했습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a32cad00",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import openai\n",
    "import tiktoken\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "_ = load_dotenv(find_dotenv()) # read local .env file\n",
    "\n",
    "openai.api_key  = os.environ['OPENAI_API_KEY']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1c9c3fd",
   "metadata": {},
   "source": [
    "#### helper function\n",
    "This may look familiar if you took the earlier course \"ChatGPT Prompt Engineering for Developers\" Course"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9adeff13",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_completion(prompt, model=\"gpt-3.5-turbo\"):\n",
    "    messages = [{\"role\": \"user\", \"content\": prompt}]\n",
    "    response = openai.ChatCompletion.create(\n",
    "        model=model,\n",
    "        messages=messages,\n",
    "        temperature=0,\n",
    "    )\n",
    "    return response.choices[0].message[\"content\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3ca1fb8",
   "metadata": {},
   "source": [
    "## Prompt the model and get a completion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6be32d1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = get_completion(\"What is the capital of France?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d129afc1",
   "metadata": {},
   "source": [
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da569f56",
   "metadata": {},
   "source": [
    "## Tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8d1352c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The reversed letters of \"lollipop\" are \"pillipol\".\n"
     ]
    }
   ],
   "source": [
    "response = get_completion(\"Take the letters in lollipop \\\n",
    "and reverse them\")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7aca499d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "p-o-p-i-l-l-o-l\n"
     ]
    }
   ],
   "source": [
    "response = get_completion(\"\"\"Take the letters in \\\n",
    "l-o-l-l-i-p-o-p and reverse them\"\"\")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92ac6d44",
   "metadata": {},
   "source": [
    "<img src=\"https://media.licdn.com/dms/image/D4D22AQH841LuwixZwg/feedshare-shrink_2048_1536/0/1687512301353?e=1691625600&v=beta&t=tl9hUuILCCsLXjSvUvE9W_mDAFV1_3lkhfHZ8w0FfUc\" width=400>\n",
    "\n",
    "For English language input, 1 token is around 4 characters, or 3/4 of a word.\n",
    "\n",
    "Token LImits\n",
    "* Different models have different limit on the number  tokens in the input \"context\"+ output completion\n",
    "* gpt3.5-turbo ~ 4000 tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9e0d54f",
   "metadata": {},
   "source": [
    "### System, User and Assistant Messages\n",
    "```\n",
    "messages =\n",
    "[\n",
    " {\"role\": \"system\",\n",
    "  \"content\": \"You are an assistant ...\"},\n",
    " {\"role\": \"user\",\n",
    "  \"content\": \"Tell me a joke \"},\n",
    " {\"role\": \"assistant\",\n",
    "  \"content\": \"Why did the chicken ...\"},\n",
    "  ...\n",
    "```\n",
    "<img src=\"mesg.PNG\" width=350>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "967e6f60",
   "metadata": {},
   "source": [
    "## Helper function (chat format)\n",
    "Here's the helper function we'll use in this course."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e9962046",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_completion_from_messages(messages, \n",
    "                                 model=\"gpt-3.5-turbo\", \n",
    "                                 temperature=0, \n",
    "                                 max_tokens=500):\n",
    "    response = openai.ChatCompletion.create(\n",
    "        model=model,\n",
    "        messages=messages,\n",
    "        temperature=temperature, # this is the degree of randomness of the model's output\n",
    "        max_tokens=max_tokens, # the maximum number of tokens the model can ouptut \n",
    "    )\n",
    "    return response.choices[0].message[\"content\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "40b29c9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In a garden so bright, a carrot did grow,\n",
      "With a leafy green top and a vibrant orange glow.\n",
      "Oh, how the carrot would dance and cheer,\n",
      "Filled with joy, bringing smiles far and near!\n",
      "\n",
      "With each sunny day and each drop of rain,\n",
      "The carrot would grow, free from any strain.\n",
      "Its sweetness and crunch, a flavor so divine,\n",
      "Bringing happiness to all, it was simply sublime!\n",
      "\n",
      "With a hop and a skip, the carrot would prance,\n",
      "Spreading laughter and giggles, in every chance.\n",
      "From salad to stew, it brought delight to each bite,\n",
      "A happy carrot, shining so bright!\n",
      "\n",
      "So let's celebrate this veggie, so jolly and merry,\n",
      "A symbol of happiness, let's not tarry.\n",
      "For a happy carrot, with its delightful flair,\n",
      "Brings joy to our plates, and a smile we gladly wear!\n"
     ]
    }
   ],
   "source": [
    "messages =  [  \n",
    "{'role':'system', \n",
    " 'content':\"You are an assistant who responds \\\n",
    "            in the style of Dr Seuss.\"},    \n",
    "{'role':'user', \n",
    " 'content':\"write me a very short poem about a happy carrot\"},  \n",
    "] \n",
    "response = get_completion_from_messages(messages, temperature=1)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9a796a11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Once upon a time, there was a cheerful carrot named Charlie who lived in a vibrant garden.\n"
     ]
    }
   ],
   "source": [
    "# length\n",
    "messages =  [  \n",
    "{'role':'system',\n",
    " 'content':'All your responses must be one sentence long.'},    \n",
    "{'role':'user',\n",
    " 'content':'write me a story about a happy carrot'},  \n",
    "] \n",
    "response = get_completion_from_messages(messages, temperature =1)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f28b223e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Once there was a happy carrot named Barry who grew tall and orange in the garden.\n"
     ]
    }
   ],
   "source": [
    "# combined\n",
    "messages =  [  \n",
    "{'role':'system',\n",
    " 'content':\"You are an assistant who \\\n",
    "responds in the style of Dr Seuss. \\\n",
    "All your responses must be one sentence long.\"},    \n",
    "{'role':'user',\n",
    " 'content':\"write me a story about a happy carrot\"},\n",
    "] \n",
    "response = get_completion_from_messages(messages, \n",
    "                                        temperature =1)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8eef8254",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_completion_and_token_count(messages, \n",
    "                                   model=\"gpt-3.5-turbo\", \n",
    "                                   temperature=0, \n",
    "                                   max_tokens=500):\n",
    "    \n",
    "    response = openai.ChatCompletion.create(\n",
    "        model=model,\n",
    "        messages=messages,\n",
    "        temperature=temperature, \n",
    "        max_tokens=max_tokens,\n",
    "    )\n",
    "    \n",
    "    content = response.choices[0].message[\"content\"]\n",
    "    \n",
    "    token_dict = {\n",
    "'prompt_tokens':response['usage']['prompt_tokens'],\n",
    "'completion_tokens':response['usage']['completion_tokens'],\n",
    "'total_tokens':response['usage']['total_tokens'],\n",
    "    }\n",
    "\n",
    "    return content, token_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b91878c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "messages = [\n",
    "{'role':'system', \n",
    " 'content':\"You are an assistant who responds in the style of Dr Seuss.\"},    \n",
    "{'role':'user',\n",
    " 'content':\"write me a very short poem about a happy carrot\"},  \n",
    "] \n",
    "response, token_dict = get_completion_and_token_count(messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "51d13fe1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Oh, the happy carrot, so bright and orange,\n",
      "Grown in the garden, a joyful forage.\n",
      "With a smile so wide, from top to bottom,\n",
      "It fills our hearts with a happy autumn.\n",
      "\n",
      "In the soil it grew, with love and care,\n",
      "Nourished by sunshine, fresh air to share.\n",
      "Its leaves so green, waving in the breeze,\n",
      "A happy carrot, it aims to please.\n",
      "\n",
      "With a crunch and a munch, it brings delight,\n",
      "A healthy snack, oh what a sight!\n",
      "From garden to table, it brings us glee,\n",
      "The happy carrot, so full of glee.\n",
      "\n",
      "So let's celebrate this veggie so grand,\n",
      "With a happy carrot in each hand.\n",
      "For in its sweetness, we find pure bliss,\n",
      "The happy carrot, a simple, joyful kiss.\n"
     ]
    }
   ],
   "source": [
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "bcf28818",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'prompt_tokens': 35, 'completion_tokens': 162, 'total_tokens': 197}\n"
     ]
    }
   ],
   "source": [
    "print(token_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9e1bafe",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
